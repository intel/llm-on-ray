port: 8000
name: fuyu-8b
route_prefix: /fuyu-8b
num_replicas: 1
cpus_per_worker: 24
gpus_per_worker: 0
deepspeed: false
workers_per_group: 2
device: cpu
ipex:
  enabled: false
  precision: bf16
model_description:
  model_id_or_path: adept/fuyu-8b
  tokenizer_name_or_path: adept/fuyu-8b
  chat_model_with_image: true
  chat_template: "llm_on_ray/inference/models/templates/template_llama2.jinja"
