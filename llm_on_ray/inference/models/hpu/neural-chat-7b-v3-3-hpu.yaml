port: 8000
name: neural-chat-7b-v3-3
route_prefix: /neural-chat-7b-v3-3
num_replicas: 1
cpus_per_worker: 0
gpus_per_worker: 0
hpus_per_worker: 1
deepspeed: false
workers_per_group: 2
device: hpu
ipex:
  enabled: false
  precision: bf16
model_description:
  model_id_or_path: Intel/neural-chat-7b-v3-3
  tokenizer_name_or_path: Intel/neural-chat-7b-v3-3
  chat_template: "llm_on_ray/inference/models/templates/template_neuralchat.jinja"
  config:
    use_auth_token: ''
