port: 8000
name: gemma-2b
route_prefix: /gemma-2b
num_replicas: 1
cpus_per_worker: 2
gpus_per_worker: 0
deepspeed: false
workers_per_group: 2
device: CPU
ipex:
  enabled: true
  precision: bf16
model_description:  
  model_id_or_path: google/gemma-2b
  tokenizer_name_or_path: google/gemma-2b
  chat_processor: ChatModelGemma
  prompt:
    intro: ''
    human_id: '<bos><start_of_turn>user
    {msg}<end_of_turn>'
    bot_id: '<bos><start_of_turn>model
    {msg}<end_of_turn>'
    stop_words: []
  config:
    use_auth_token: ' '
