port: 8000
name: gemma-2b
route_prefix: /gemma-2b
num_replicas: 1
device: cpu
cpus_per_worker: 24
vllm:
  enabled: true
  precision: bf16
model_description:
  model_id_or_path: google/gemma-2b
  tokenizer_name_or_path: google/gemma-2b
  config:
    use_auth_token: ' '
  chat_template: "llm_on_ray/inference/models/templates/template_gemma.jinja"
