port: 8000
name: gemma-2b
route_prefix: /gemma-2b
num_replicas: 1
cpus_per_worker: 2
gpus_per_worker: 0
deepspeed: false
workers_per_group: 2
device: cpu
ipex:
  enabled: true
  precision: bf16
model_description:
  model_id_or_path: google/gemma-2b
  tokenizer_name_or_path: google/gemma-2b
  config:
    use_auth_token: ' '
  chat_template: "llm_on_ray/inference/models/templates/template_gemma.jinja"
