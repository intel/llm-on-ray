port: 8000
name: fuyu-8b
route_prefix: /fuyu-8b
cpus_per_worker: 24
gpus_per_worker: 0
deepspeed: false
workers_per_group: 2
device: "cpu"
ipex:
  enabled: false
  precision: bf16
model_description:
  model_id_or_path: /mnt/nvme0n1/chendi/llm-on-ray/models/adept/fuyu-8b
  tokenizer_name_or_path: /mnt/nvme0n1/chendi/llm-on-ray/models/adept/fuyu-8b
  chat_processor: ChatModelwithImage
  input_processor: FuyuProcessor
  model_loader: FuyuForCausalLM
  prompt:
    intro: ''
    human_id: '[INST] {msg} [/INST]

      '
    bot_id: ''
    stop_words: []
  config:
    use_auth_token: ''
